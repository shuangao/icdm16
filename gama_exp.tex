In this section, we show empirical results of our algorithm for different transferring situations on two image benchmark datasets: MNIST\footnote{http://yann.lecun.com/exdb/mnist/} \cite{lampert2009learning} and USPS\footnote{http://www.cs.nyu.edu/~roweis/data.html}. We test the performance of our algorithm in different scenarios and show that SMTLe can outperform the other baseline transfer methods when the source and target domains are related and alleviate negative transfer while other baseline methods suffer.
\subsection{Dataset}
The MNIST database \cite{lecun1998gradient} is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by re-mixing the samples from NIST's original datasets. Data in MNIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels. In our experiment, we use a sub-set of MNIST dataset, containing 6,000 examples for 10 classes (from digit 0 to 9). We also use another handwritten digital dataset USPS \cite{hull1994database}. USPS contains 11,000 images and the data is evenly distributed among 10 classes, i.e. 1,100 examples for each digit. Each digit is represented as a 16x16 greyscale image.

For each of the datasets, we randomly split it into 3 sets: the large source dataset (100 examples per class for both dataset) to train the source models, the small target training set (5/10/15/20/25 examples per class for both datasets) to train target model and the large target testset (4700 and 9700 examples for MNIST and USPS, respectively) to evaluate the performance of the target model.

\subsection{Baseline methods and experiment setup}
We compare our algorithm with two kinds of baselines. The first one is the methods without leveraging any prior knowledge (no transfer baselines). The second consists of some previous methods in HTL. 

We select 2 no transfer baselines:
\textbf{No transfer (NT):} LS-SVM trained only on target data. Any transfer algorithm that performs worse than it suffers from negative transfer. \textbf{Batch:} We combined the source and target data, assuming that we have full access to all data, to train the LS-SVM. The result of this baseline might be considered as the best performance achieved when no noise is added to the source data.


We select the 3 HTL baseline methods, \textbf{MKTL \cite{jie2011multiclass}}, \textbf{Multi-KT \cite{tommasi2014learning}}, \textbf{PMT-SVM} \cite{aytar2011tabula} as our transfer baselines\footnote{Algorithms are implemented by the original authors. MKTL and Multi-KT can be downloaded from http://tatianatommasi.wix.com/tatianatommasi\#!3/ckra. PMT-SVM can be found from https://www.robots.ox.ac.uk/~vgg/software/tabularasa/}. MKTL also use feature augmentation for the target data, but with a more aggressive strategy. For Multi-KT, there are 3 different strategies, Weighted Multi-KT, Single-KT and Average-KT. We use all the 3 strategies in our experiments and denote them as MKT\_m, MKT\_s and MKT\_a respectively. For PMT-SVM, we use grid search on $\{0.1,0.2,...,1\}$ for the weights of its projection matrix and report the best performance.
Also, we include the method \textbf{Feature+} discussed in Section \ref{sec:prob} which solves the hyperplane $\hat{w}$ directly. 
For our method \textbf{SMTLe}, we implement 2 adaptation strategies single-adaptation (SMTLe\_s) and multi-adaptation (SMTLe\_m). For SMTLe\_s, we choose the model that distinguishes the corresponding class in the source, i.e. choose the model to distinguish the class digit 1 in the source as the single source model for target binary model of the class digit 1. For SMTLe\_m, we choose all the source models for each target binary model.

%\textbf{MKTL \cite{jie2011multiclass}:} This method uses the output of source models as extra feature inputs and automatically determine from which source models to transfer and how much to transfer.


%\textbf{MULTI-KT \cite{tommasi2014learning}:} This method has similar idea with MKTL. It uses LOO error to determine how much to transfer from source models and convert it into solving the convex optimization problem.

%\textbf{MULTIpLE \cite{kuzborskij2013n}:} The basic setting of this method is similar to ours. It is designed to balance the performance between learning the new category and preserving the model from prior knowledge.

For all the experiments in this section, we adopt the same strategy as \cite{kuzborskij2013n} and \cite{tommasi2014learning}, using RBF kernels on RBF hyper-parameter $\gamma = \{2^{-5},2^{-4},...,2^8\}$. The penalty parameter $C$ is tuned via cross-validation on $\{10^{-5},10^{-4},...,10^8\}$ and the optimal value is reused for all the algorithms. 
The transfer regularization parameter $\lambda$ in SMTLe is also set via cross-validation on $\{10^{-3},10^{-2},...,10\}$ respectively. For both datasets, we use the raw pixels as the input feature.

As the baseline methods can only use the linear model as their source, in this paper, the SVM model trained from the source data is used for all the transfer methods.
To generate different source models with different relatedness to the target domain. We add different levels of noise to the source training data and train the source models from the noisy source data. When there is no noise added to the source data, the source and target domain are identical (strongly related). As we add more noise, the distribution of the data in source and target domain become more different, i.e. the source and target domain become less related (see Figure \ref{fig:noise}). 

\begin{figure}
	\centering
	\includegraphics[scale=0.45]{fig/noise.png}
	\caption{We add the noise (Salt \& Pepper noise) to the source data to generate the source domain with different relatedness to the target domain. From the images we  can see that the source domain is still related to the target domain in different level of the noise rate}\label{fig:noise}
\end{figure}

\subsection{Experiment result \& analysis}
\begin{table*}[htbp]
	\subfloat[Results on MNIST]{\resizebox{0.5\textwidth}{!}{
			\begin{tabular}{|c|c|c|c|c|c|c|c|}
				\hline 
				& \multicolumn{7}{c|}{Noise Level} \\ \hline
				& 0.0 & 0.2 & 0.3 & 0.5 & 0.8 & 0.9 & 1.0\\ \hline
				SMTLe\_s & \textbf{87.23} & \textbf{86.40} & \textbf{85.81} & \textbf{84.63} & \textbf{81.51} & \textbf{79.67} & \textbf{78.10}\\ 
				SMTLe\_m & 82.94 & 80.20 & 79.05 & 76.56 & 72.10 & 69.57 & 68.09\\ 
				MKT\_{m} & 61.96* & 57.14* & 55.18* & 50.67* & 45.16* & 43.72* & 42.73*\\ 
				MKT\_{s} & 86.63 & 82.33 & 79.78 & 74.61 & 67.51 & 65.52 & 64.06\\ 
				MKT\_{a} & 62.94 & 63.04 & 63.03 & 62.91 & 62.93 & 62.98 & 62.89\\ 
				MKTL & 70.06 & 55.63* & 60.42* & 41.57* & 40.44* & 42.22* & 31.44*\\ 
				PMT & 63.54 & 63.54 & 63.54 & 63.54 & 63.54 & 63.54 & 63.54\\ 
				Feature+ & 66.99 & 61.72* & 59.13* & 54.27* & 46.46* & 44.44* & 42.67*\\ 
				NT & 62.87 & 62.87 & 62.87 & 62.87 & 62.87 & 62.87 & 62.87\\ 
				Batch & 87.39 & 84.42 & 82.40 & 76.83 & 62.86* & 57.33* & 51.16*\\ 
				\hline\end{tabular}}}%{body}
	\subfloat[Results on USPS]{
		\resizebox{0.5\textwidth}{!}{
			\begin{tabular}{|c|c|c|c|c|c|c|c|}
				\hline 
				& \multicolumn{7}{c|}{Noise Level} \\ \hline
				& 0.0 & 0.2 & 0.3 & 0.5 & 0.8 & 0.9 & 1.0\\ \hline
				SMTLe\_s & \textbf{91.12} & 89.79 & 89.23 & 88.06 & 86.22 & 85.33 & 84.60\\ 
				SMTLe\_m & 90.78 & \textbf{89.85} & \textbf{89.42} & \textbf{88.55} & \textbf{86.80} & \textbf{85.96} & \textbf{84.91}\\ 
				MKT\_{m} & 86.80 & 84.80 & 83.57 & 81.02 & 75.96 & 74.53* & 72.73*\\ 
				MKT\_{s} & 64.18* & 61.39* & 61.80* & 62.93* & 64.85* & 65.29* & 65.55*\\ 
				MKT\_{a} & 75.76 & 75.76 & 75.75 & 75.79 & 75.75 & 75.78 & 75.84\\ 
				MKTL & 90.24 & 88.13 & 86.20 & 86.07 & 81.82 & 80.18 & 80.14\\ 
				PMT & 75.89 & 75.89 & 75.9 & 75.88 & 75.88 & 75.88 & 75.87\\ 
				Feature+ & 88.42 & 86.56 & 85.28 & 83.23 & 79.79 & 78.68 & 77.17\\ 
				NT & 75.75 & 75.75 & 75.75 & 75.75 & 75.75 & 75.75 & 75.75\\ 
				Batch & 91.65 & 90.38 & 89.58 & 87.36 & 82.55 & 80.52 & 77.84\\ 
				\hline\end{tabular}}}%
	\caption{Experiment results on 5 examples per class in target training set. We show the percentage of accuracy across the 10 classes on different noise level. We use "*" to denote the results suffer from negative transfer}\label{tab:rs}
\end{table*}%

We perform the algorithms on different scenarios where the different levels of noise is added to the source data to train the source models. Still we use LS-SVM to train the source models. For each dataset, we use the accuracy across the 10 classes as the criterion to evaluate the performance of the algorithms. We randomly split the original datasets into 3 sets and run 10 times to report the average performance. 

We show the performance of different algorithms on the two datasets under different noise levels in Table \ref{tab:rs} where only 5 positive examples for each class are used in target training set. We show more results with different training sizes in the target set in Table \ref{tab:mnist} and Table \ref{tab:usps}. From the experiments results we can see that more transfer methods suffer from negative transfer in MNIST than in USPS. This may be caused by the different data dimension (784 in MNIST VS 256 in USPS). As we discussed in Section \ref{sec:prob}, if there are more parameters to be determined and the source knowledge is not leveraged properly, the target model is more likely to suffer from negative transfer.
The rest of the analysis is based on the results from Table \ref{tab:rs} and we can observe similar results on other tables.

From Table \ref{tab:rs} we can see that when there is no noise in the source data, most transfer algorithms can leverage the knowledge of the source model. Our methods SMTLe\_s and SMTLe\_m achieve the best performance among all transfer methods, but still slightly underperform the Batch method which can access all the data from both source and target training data. We may expect better performances of PMT-SVM as we reduce the interval of the grid search, which is however, more computational expensive.  
It is worthy to notice that the MKT\_m in MNIST and MKT\_s in USPS suffer from negative transfer even though there is no noise in the source data. Arguably, this is caused by their less expressive manner of using the regularization term. In fact, they limit the transfer parameters within the ball of unit radius (its default setting). The results could be improved if a better regularization can be found.
The results in Table \ref{tab:rs} also reflects that, as we add more noise into the source data, some of the transfer algorithms start to suffer from negative transfer. It is not surprising that all methods (except for NT as no source knowledge is used) get a decreased performance. However, our methods can still outperform the other methods. The performance of MKTL in MNIST drops almost 39\%. MKTL tries to use aggressive augmentation approach and there are many parameters to learn. Therefore, it is more difficult to find a good solution when the source and target domain are not very related. 
In our methods, We use a simpler feature augmentation approach. The optimal transfer parameters can both limit the VC dimension and reduce empirical risk at the same time. Compared to Feature+ which suffers from negative transfer when the noise level increases, our two methods can alleviate negative transfer and achieve lower generalization risk even though the source models become less related to the target domain. We can also see that there are just 3 methods that don't suffer from negative transfer in both datasets, i.e. SMTLe\_s, SMTLe\_m and MKT\_a. However, we can see that MKT\_a is a more conservative method which is reluctant to leverage the knowledge from the source model. In fact, it assigns identical weights to all source models. Therefore, it is unable to fully exploit the knowledge from the source models.

In summary, in this section, we empirically evaluate the performance of our method in different scenarios where there is different relatedness between the source and target domains. Comparing with the baseline methods, we can see that our method can effectively leverage the knowledge from the source models and alleviate negative transfer when other baseline methods suffer.

\input{rs.tex}